{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450fff6e",
   "metadata": {},
   "source": [
    "# PAQUETES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ebe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las liberías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "#import pydotplus\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502ac91",
   "metadata": {},
   "source": [
    "# PREPARACIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34526b-79e5-4094-a5c2-3650979f8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el csv\n",
    "df=pd.read_csv(\"cleveland_cardiaco.csv\",sep=\",\")\n",
    "#Añadimos los nombres de las columnas\n",
    "headers = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"]\n",
    "df.columns = headers\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56fbeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los valores que tiene cada columna y cuantas veces aparece cada uno de ellos\n",
    "for i in df.columns:\n",
    "    print(i,df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e11ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Información del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc018b-3361-460c-9820-938856a66e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos las filas en las que aparezca el valor \"?\"\n",
    "df=df[df!=\"?\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d992e248-2b18-4fa8-be53-8f3f33c18883",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Información del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].astype(int)\n",
    "df['sex'] = df['sex'].astype(int)\n",
    "df['cp'] = df['cp'].astype(int)\n",
    "df['trestbps'] = df['trestbps'].astype(int)\n",
    "df['chol'] = df['chol'].astype(int)\n",
    "df['fbs'] = df['fbs'].astype(int)\n",
    "df['restecg'] = df['restecg'].astype(int)\n",
    "df['thalach'] = df['thalach'].astype(int)\n",
    "df['exang'] = df['exang'].astype(int)\n",
    "df['slope'] = df['slope'].astype(int)\n",
    "df['oldpeak'] = df['oldpeak'].astype(float)\n",
    "df['thal'] = df['thal'].astype(float)\n",
    "df['ca'] = df['ca'].astype(float)\n",
    "df['thal'] = df['thal'].astype(float)\n",
    "df['ca'] = df['ca'].astype(int)\n",
    "df['thal'] = df['thal'].astype(int)\n",
    "df['num'] = df['num'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746229a-97f2-4022-acf5-5542d253b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el dataset como csv\n",
    "df.to_csv(\"cleveland_cardiaco_py.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la frecuencia de los valores de clase en todo el DataFrame\n",
    "frecuencia_clase = df['num'].value_counts()\n",
    "\n",
    "# Crea un gráfico de barras para visualizar la frecuencia de los valores de clase\n",
    "plt.bar(frecuencia_clase.index, frecuencia_clase.values)\n",
    "plt.xlabel('Diagnóstico')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962378a0",
   "metadata": {},
   "source": [
    "# PREPROCESAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d24ec-22ae-41fe-ba9f-af18c0e1b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos entrada y salida\n",
    "x = df.iloc[:, :-1]  # Características (atributos)\n",
    "y = df.iloc[:, -1]  # Etiquetas (salida)\n",
    "# Dividimos en datos de entrenamiento y de validación\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "x_train.columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\"]\n",
    "x_test.columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\"]\n",
    "\n",
    "#Tamaños\n",
    "x.shape, y.shape\n",
    "\n",
    "x_train.shape, y_train.shape\n",
    "\n",
    "x_test.shape, y_test.shape\n",
    "\n",
    "# Calculamos el máximo y mínimo\n",
    "maxs = np.max(x_train, axis=0)\n",
    "mins = np.min(x_train, axis=0)\n",
    "\n",
    "ranges = maxs - mins\n",
    "\n",
    "# Normalizamos las variables\n",
    "x_train = (x_train - mins) / ranges\n",
    "x_test = (x_test - mins) / ranges\n",
    "\n",
    "# Calcula las frecuencias de clase en y_train\n",
    "class_frequencies = y_train.value_counts()\n",
    "\n",
    "# Calcula los pesos para cada clase  \n",
    "#class_weights = {cls: 1.0 / freq for cls, freq in class_frequencies.items()}\n",
    "#class_weights_int = {int(cls[0]): weight for cls, weight in class_weights.items()}\n",
    "\n",
    "# Calcula los pesos de clase\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=y.unique(), y=y)\n",
    "\n",
    "# Crea un diccionario con los pesos de clase\n",
    "class_weights_int = {cls: weight for cls, weight in zip(y.unique(), class_weights)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e4ab9",
   "metadata": {},
   "source": [
    "# MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a638eb5b",
   "metadata": {},
   "source": [
    "## Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead257be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo genérico\n",
    "DT = DecisionTreeClassifier(class_weight=class_weights_int)\n",
    "# entrenamos el modelo\n",
    "DT.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_DT = DT.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_DT))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    DT, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "DT_prec=score.mean()\n",
    "print(\"cross_value: \", DT_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_DT)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver opciones con otros parametros\n",
    "DT_combinaciones={}\n",
    "# parametros\n",
    "splitter_ = [\"best\", \"random\"]\n",
    "criterion_ = [\"gini\", \"entropy\"]\n",
    "max_features_ = [None,\"sqrt\", \"log2\"]\n",
    "porc_ = [0.2, 0.3]\n",
    "# combinaciones\n",
    "for c in criterion_:\n",
    "    for m in max_features_:\n",
    "        for s in splitter_:\n",
    "            for p in [1, 2]:\n",
    "                vector_parametros=[c,m,s,porc_[p-1]]\n",
    "                # dividimos las instancias\n",
    "                x_train, x_test, y_train, y_test = train_test_split(\n",
    "                    x, y, test_size=porc_[p - 1], random_state=42, shuffle=True\n",
    "                )\n",
    "                x_train.columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\"]\n",
    "                x_test.columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\"]\n",
    "\n",
    "                # modelo\n",
    "                DT = DecisionTreeClassifier(criterion=c, max_features=m, splitter=s, class_weight=class_weights_int)\n",
    "                # entrenamos el modelo\n",
    "                DT.fit(x_train, y_train)\n",
    "                # hacer predicciones\n",
    "                predicciones_DT = DT.predict(x_test)\n",
    "                # calculamos la exactitud del modelo\n",
    "                acc_1 = accuracy_score(y_test, predicciones_DT)\n",
    "                # cross value\n",
    "                kfold = StratifiedKFold(10)\n",
    "                score = cross_val_score(DT, x_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "                print(\n",
    "                    c,\n",
    "                    \",\",\n",
    "                    m,\n",
    "                    \"y\",\n",
    "                    s,\n",
    "                    \"(\",\n",
    "                    porc_[p - 1],\n",
    "                    \")\",\n",
    "                    \"-> accuracy_score: \",\n",
    "                    acc_1,\n",
    "                    \"//\",\n",
    "                    \"cross_value: \",\n",
    "                    score.mean()\n",
    "                )\n",
    "                # añadimos al diccionario esta combinación\n",
    "                DT_combinaciones[score.mean()]=vector_parametros\n",
    "                \n",
    "# calculamos la precisión máxima\n",
    "DT_max_prec = max(DT_combinaciones)\n",
    "# miramos con que parámetros se consigue esta precisión\n",
    "DT_mejor_vector_parametros = DT_combinaciones[DT_max_prec]\n",
    "print(\"mejores resultados con los parametros -> \",DT_mejor_vector_parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5affd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mejor modelo (utilizando el vector conseguido anteriormente)\n",
    "DT_mejor = DecisionTreeClassifier(criterion=DT_mejor_vector_parametros[0], max_features=DT_mejor_vector_parametros[1], splitter=DT_mejor_vector_parametros[2], class_weight=class_weights_int)\n",
    "# dividimos las instancias \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=DT_mejor_vector_parametros[3], random_state=42, shuffle=True)\n",
    "\n",
    "# entrenamos el modelo\n",
    "DT_mejor.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_DT_mejor = DT_mejor.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_DT_mejor,zero_division=1))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    DT_mejor, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "DT_mejor_prec=score.mean()\n",
    "print(\"cross_value: \", DT_mejor_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_DT_mejor)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5b40f",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo genérico\n",
    "y_ravel= np.ravel(y)\n",
    "RF = RandomForestClassifier(class_weight=class_weights_int)\n",
    "# entrenamos el modelo\n",
    "y_train=y_train.values.ravel()\n",
    "RF.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_RF = RF.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_RF,zero_division=0))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    RF, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "RF_prec=score.mean()\n",
    "print(\"cross_value: \", RF_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_RF)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32407d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver opciones con otros parámetros\n",
    "RF_combinaciones={}\n",
    "# parametros\n",
    "criterion_ = [\"gini\", \"entropy\"]\n",
    "max_features_ = [None,\"sqrt\", \"log2\"]\n",
    "porc_ = [0.2, 0.3]\n",
    "# combinaciones\n",
    "for c in criterion_:\n",
    "    for m in max_features_:\n",
    "        for p in [1, 2]:\n",
    "            vector_parametros=[c,m,porc_[p-1]]\n",
    "            # dividimos las instancias\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=porc_[p - 1], random_state=42, shuffle=True)\n",
    "            y_train=y_train.values.ravel()\n",
    "            # modelo\n",
    "            RF = RandomForestClassifier(criterion=c, max_features=m, class_weight=class_weights_int)\n",
    "            # entrenamos el modelo\n",
    "            RF.fit(x_train, y_train)\n",
    "            # hacer predicciones\n",
    "            predicciones_RF = RF.predict(x_test)\n",
    "            # calculamos la exactitud del modelo\n",
    "            acc_1 = accuracy_score(y_test, predicciones_RF)\n",
    "            # cross value\n",
    "            kfold = StratifiedKFold(10)\n",
    "            score = cross_val_score(RF, x_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "            print(\n",
    "                c,\n",
    "                \"y\",\n",
    "                m,\n",
    "                \"(\",\n",
    "                porc_[p - 1],\n",
    "                \")\",\n",
    "                \"-> accuracy_score: \",\n",
    "                acc_1,\n",
    "                \"//\",\n",
    "                \"cross_value: \",\n",
    "                score.mean()\n",
    "            )\n",
    "            # añadimos al diccionario esta combinación\n",
    "            RF_combinaciones[score.mean()]=vector_parametros\n",
    "                \n",
    "# calculamos la precisión máxima\n",
    "RF_max_prec = max(RF_combinaciones)\n",
    "# miramos con que parámetros se consigue esta precisión\n",
    "RF_mejor_vector_parametros = RF_combinaciones[RF_max_prec]\n",
    "print(\"mejores resultados con los parametros -> \",RF_mejor_vector_parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mejor modelo (utilizando el vector conseguido anteriormente)\n",
    "RF_mejor = RandomForestClassifier(criterion=RF_mejor_vector_parametros[0], max_features=RF_mejor_vector_parametros[1], class_weight=class_weights_int)\n",
    "# dividimos las instancias \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=RF_mejor_vector_parametros[2], random_state=42, shuffle=True)\n",
    "y_train=y_train.values.ravel()\n",
    "# entrenamos el modelo\n",
    "RF_mejor.fit(x_train, y_train)\n",
    "# hacer predicciones\n",
    "pred_RF_mejor = RF_mejor.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_RF_mejor,zero_division=1))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    RF_mejor, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "RF_mejor_prec=score.mean()\n",
    "print(\"cross_value: \", RF_mejor_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_RF_mejor)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3924524",
   "metadata": {},
   "source": [
    "## Redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214bc390",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = [\"adam\", \"SGD\", \"RMSprop\", \"adagrad\", \"adamax\"]\n",
    "RN_combinaciones = {}\n",
    "\n",
    "# Separa los atributos y las etiquetas de diagnóstico\n",
    "x = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values \n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escala los atributos para normalizarlos\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# ESTRUCTURA 1\n",
    "RNmodel = Sequential()\n",
    "\n",
    "# Agrega capas densas (totalmente conectadas) al modelo\n",
    "RNmodel.add(Dense(64, activation='relu', input_shape=(13,)))  # Capa oculta 1\n",
    "RNmodel.add(Dense(64, activation='relu'))  # Capa oculta 2\n",
    "RNmodel.add(Dense(5, activation='softmax'))  # Capa de salida (5 valores posibles)\n",
    "\n",
    "for i in optim:\n",
    "    # Compila el modelo\n",
    "    RNmodel.compile(optimizer=i, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrena el modelo\n",
    "    RNmodel.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "    y_pred_prob = RNmodel.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Calcular precisión\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "    print(\"Precisión:\", precision)\n",
    "\n",
    "    # Calcular matriz de confusión\n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    ConfusionMatrixDisplay(matriz_confusion).plot()\n",
    "    plt.show()\n",
    "\n",
    "    RN_combinaciones[precision] = [1, i]\n",
    "\n",
    "# ESTRUCTURA 2\n",
    "RNmodel = Sequential()\n",
    "\n",
    "# Agrega capas densas (totalmente conectadas) al modelo\n",
    "RNmodel.add(Dense(128, activation='relu', input_shape=(13,)))  # Capa oculta 1\n",
    "RNmodel.add(Dense(64, activation='relu'))  # Capa oculta 2\n",
    "RNmodel.add(Dense(32, activation='relu'))  # Capa oculta 3\n",
    "RNmodel.add(Dense(5, activation='softmax'))  # Capa de salida (5 valores posibles)\n",
    "\n",
    "for i in optim:\n",
    "    # Compila el modelo\n",
    "    RNmodel.compile(optimizer=i, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrena el modelo\n",
    "    RNmodel.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "    y_pred_prob = RNmodel.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Calcular precisión\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "    print(\"Precisión:\", precision)\n",
    "\n",
    "    # Calcular matriz de confusión\n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    ConfusionMatrixDisplay(matriz_confusion).plot()\n",
    "    plt.show()\n",
    "\n",
    "    RN_combinaciones[precision] = [2, i]\n",
    "\n",
    "# ESTRUCTURA 3\n",
    "RNmodel = Sequential()\n",
    "\n",
    "# Agrega capas densas (totalmente conectadas) al modelo\n",
    "RNmodel.add(Dense(64, activation='relu', input_shape=(13,)))  # Capa oculta 1\n",
    "RNmodel.add(Dense(128, activation='relu'))  # Capa oculta 2\n",
    "RNmodel.add(Dense(64, activation='relu'))  # Capa oculta 3\n",
    "RNmodel.add(Dense(32, activation='relu'))  # Capa oculta 4\n",
    "RNmodel.add(Dense(5, activation='softmax'))  # Capa de salida (5 valores posibles)\n",
    "\n",
    "for i in optim:\n",
    "    # Compila el modelo\n",
    "    RNmodel.compile(optimizer=i, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrena el modelo\n",
    "    RNmodel.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "    y_pred_prob = RNmodel.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Calcular precisión\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "    print(\"Precisión:\", precision)\n",
    "\n",
    "    # Calcular matriz de confusión\n",
    "    matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de confusión:\")\n",
    "    ConfusionMatrixDisplay(matriz_confusion).plot()\n",
    "    plt.show()\n",
    "\n",
    "    RN_combinaciones[precision] = [3, i]\n",
    "\n",
    "print(RN_combinaciones)\n",
    "# calculamos la precisión máxima\n",
    "RN_max_prec = max(RN_combinaciones)\n",
    "# miramos con qué parámetros se consigue esta precisión\n",
    "RN_mejor_vector_parametros = RN_combinaciones[RN_max_prec]\n",
    "print(\"Mejores resultados con los parámetros:\", RN_mejor_vector_parametros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo\n",
    "\n",
    "RNmodel_mejor = Sequential()\n",
    "\n",
    "if RN_mejor_vector_parametros[0]==1:\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu', input_shape=(13,)))  # Capa oculta 1\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu'))  # Capa oculta 2\n",
    "    RNmodel.add(Dense(5, activation='softmax'))  # Capa de salida (5 valores posibles)\n",
    "elif RN_mejor_vector_parametros[0]==2:\n",
    "    RNmodel_mejor.add(Dense(128, activation='relu', input_shape=(13,)))  # Capa oculta 1\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu'))  # Capa oculta 2\n",
    "    RNmodel_mejor.add(Dense(32, activation='relu'))  # Capa oculta 3\n",
    "    RNmodel_mejor.add(Dense(5, activation='softmax'))  # Capa de salida (5 valores posibles)\n",
    "elif RN_mejor_vector_parametros[0]==3:\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu', input_shape=(13,)))  # Capa oculta 1\n",
    "    RNmodel_mejor.add(Dense(128, activation='relu'))  # Capa oculta 2\n",
    "    RNmodel_mejor.add(Dense(64, activation='relu'))  # Capa oculta 3\n",
    "    RNmodel_mejor.add(Dense(32, activation='relu'))  # Capa oculta 4\n",
    "    RNmodel_mejor.add(Dense(5, activation='softmax'))  # Capa de salida (5 valores posibles)\n",
    "# Compila el modelo\n",
    "RNmodel_mejor.compile(optimizer=RN_mejor_vector_parametros[1], loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrena el modelo\n",
    "RNmodel_mejor.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "y_pred_prob = RNmodel_mejor.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Calcular precisión\n",
    "RN_mejor_prec = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión:\", RN_mejor_prec)\n",
    "\n",
    "# Calcular matriz de confusión\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "ConfusionMatrixDisplay(matriz_confusion).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683524e2",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score=[]\n",
    "max_score=0\n",
    "best_k=0\n",
    "for k in range(2,30):\n",
    "    knn_model=KNeighborsClassifier(n_jobs=-1,n_neighbors=k)\n",
    "    score=cross_val_score(knn_model,x_train,y_train,cv=5,scoring='accuracy')\n",
    "    if score.mean()>max_score:\n",
    "        max_score=score.mean()\n",
    "        best_k=k\n",
    "    avg_score.append(score.mean())\n",
    "\n",
    "print([best_k,max(avg_score)])\n",
    "\n",
    "max_index = avg_score.index(max(avg_score))\n",
    "max_value = max(avg_score)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(range(2, 30), avg_score, color='blue', linewidth=2)  \n",
    "plt.scatter(max_index+2, max_value, color='darkblue', marker='o', s=200)  \n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0dec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo\n",
    "KNN=KNeighborsClassifier(n_neighbors=best_k)\n",
    "# entrenamos el modelo\n",
    "KNN.fit(x_train,y_train)\n",
    "# hacer predicciones\n",
    "pred_KNN = KNN.predict(x_test)\n",
    "# informe\n",
    "print(classification_report(y_test,pred_KNN,zero_division=0))\n",
    "# cross value\n",
    "kfold = StratifiedKFold(10)\n",
    "score = cross_val_score(\n",
    "    KNN, x_train, y_train, cv=kfold, scoring=\"accuracy\"\n",
    ")\n",
    "KNN_prec=score.mean()\n",
    "print(\"cross_value: \", KNN_prec)\n",
    "# matriz de confusión\n",
    "mat_conf = confusion_matrix(y_test, pred_KNN)\n",
    "ConfusionMatrixDisplay(mat_conf).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e35d172",
   "metadata": {},
   "source": [
    "# DIAGNOSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ded7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_v=str(input(\"Ahora introduciras los datos médicos del paciente con nombre o identificador: \"))\n",
    "\n",
    "age_v=int(input(\"edad en años: \"))\n",
    "sex_v=int(input(\"sexo (0=mujer)(1=hombre): \"))\n",
    "cp_v=int(input(\"tipo de angina (1=típico)(2=atípico)(3=no es angina)(4=asintomático): \"))\n",
    "trestbps_v=int(input(\"presión sanguínea entre latidos en mm Hg: \"))\n",
    "chol_v=int(input(\"colesterol en sangre en mg/dL: \"))\n",
    "fbs_v=int(input(\"glucosa en sangre en ayunas (0=menos de 120 mg/dL)(1=más de 120 mg/dL): \"))\n",
    "restecg_v=int(input(\"reultado electrocardiográfico en reposo (0=normal)(1=anormal en la onda ST-T)(2=hipertrofia ventricular izq): \"))\n",
    "thalach_v=int(input(\"frecuencia carduaca máxima durante el ejercicio: \"))\n",
    "exang_v=int(input(\"angina durante el ejercicio (0=no)(1=sí): \"))\n",
    "oldpeak_v=float(input(\"diferencia de altura del segmento ST: \"))\n",
    "slope_v=int(input(\"pendiente del segmento ST durante el ejercicio máximo (1=ascendente)(2=plano)(3=descendente): \"))\n",
    "ca_v=int(input(\"número de vasos principales colorados durante la fluoroscopia (de 0 a 3): \"))\n",
    "thal_v=int(input(\"diagnóstico de la enfermedad cardiaca (3=sin defectos)(6=defecto fijo)(7=defecto reversible): \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2d69b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pac=[age_v, sex_v, cp_v, trestbps_v,chol_v,fbs_v,restecg_v,thalach_v, exang_v, oldpeak_v, slope_v, ca_v, thal_v]\n",
    "#pac=[65,1,4,162,287,0,2,107,1,1.5,2,3,3]\n",
    "#nombre_v=\"Aitor\"\n",
    "\n",
    "#Crear los DataFrames que necesitaremos\n",
    "df_diagnostico = pd.DataFrame(columns=['Método', 'Características', 'Precisión', 'Diagnóstico'])\n",
    "\n",
    "df_datos=pd.DataFrame({'medida':['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal'],\n",
    "                     'valor':pac})\n",
    "\n",
    "df_nombre=pd.DataFrame({'nombre':[nombre_v]})\n",
    "\n",
    "# Predecir diagnóstico con diferentes métodos\n",
    "DT_predict=int(DT_mejor.predict([pac]))\n",
    "RF_predict=int(RF_mejor.predict([pac]))\n",
    "pac_scaled = scaler.transform([pac])  # Escala el vector pac\n",
    "y_pred_prob = RNmodel_mejor.predict(pac_scaled)\n",
    "RN_predict = np.argmax(y_pred_prob, axis=1)\n",
    "KNN_predict=int(KNN.predict([pac]))\n",
    "    \n",
    "df_diagnostico = df_diagnostico.append({'Método': 'Árbol de decisión', 'Características': DT_mejor_vector_parametros, 'Precisión': DT_mejor_prec, 'Diagnóstico': DT_predict}, ignore_index=True)\n",
    "df_diagnostico = df_diagnostico.append({'Método': 'Random Forest', 'Características': RF_mejor_vector_parametros, 'Precisión': RF_mejor_prec, 'Diagnóstico': RF_predict}, ignore_index=True)\n",
    "df_diagnostico = df_diagnostico.append({'Método': 'Redes neuronales', 'Características': RN_mejor_vector_parametros, 'Precisión': RN_mejor_prec, 'Diagnóstico': RN_predict[0]}, ignore_index=True)\n",
    "df_diagnostico = df_diagnostico.append({'Método': 'KNN', 'Características': 'K='+ str(best_k), 'Precisión': KNN_prec, 'Diagnóstico': KNN_predict}, ignore_index=True)\n",
    "\n",
    "df_diagnostico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcbf162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos los dataset como csv\n",
    "df_datos.to_csv(\"datospac_cardiopatia_py.csv\", index=False)\n",
    "df_diagnostico.to_csv(\"diagnostico_cardiopatia_py.csv\", index=False)\n",
    "df_nombre.to_csv(\"nombrepac_cardiopatia_py.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
